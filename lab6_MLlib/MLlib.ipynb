{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gm9aYzTDTTU"
   },
   "source": [
    "# MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YBM19ZBQDTTX"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF, QuantileDiscretizer, StringIndexer, Tokenizer, VectorAssembler\n",
    "from pyspark.ml.stat import Correlation, KolmogorovSmirnovTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "u1Z_Q8lZDTTZ",
    "outputId": "a1491224-f7c1-4336-e3d5-f1e11b1cfb95",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-HNLVNJD.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1760a65c040>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7GDDu-2DTTa"
   },
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Titanic dataset](https://www.kaggle.com/c/titanic/data?select=train.csv) will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwIzAVYsGkEC",
    "outputId": "890b1285-c40d-45d7-9b77-69f55c5018ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----------+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|        C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|   53.1|       C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|   17463|51.8625|        E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1| PP 9549|   16.7|         G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  113783|  26.55|       C103|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|  248698|   13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|  113788|   35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|   19950|  263.0|C23 C25 C27|       S|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|PC 17572|76.7292|        D33|       C|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|  113509|61.9792|        B30|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "[('PassengerId', 'int'), ('Survived', 'int'), ('Pclass', 'int'), ('Name', 'string'), ('Sex', 'string'), ('Age', 'double'), ('SibSp', 'int'), ('Parch', 'int'), ('Ticket', 'string'), ('Fare', 'double'), ('Cabin', 'string'), ('Embarked', 'string')]\n"
     ]
    }
   ],
   "source": [
    "filename = \"titanic_train.csv\"\n",
    "titanic_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(inferSchema=\"true\", header=\"true\")\n",
    "    .load(filename)\n",
    ")\n",
    "titanic_df = titanic_df.dropna(how=\"any\")\n",
    "\n",
    "titanic_df.show(10)\n",
    "print(titanic_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45tDK3AbDTTb"
   },
   "source": [
    "### Descriptive statistics\n",
    "\n",
    "Calculate descriptive statistics for \"Age\" and \"Fare\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wH4SqCVgjYzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               Age|\n",
      "+-------+------------------+\n",
      "|  count|               183|\n",
      "|   mean|  35.6744262295082|\n",
      "| stddev|15.643865966849717|\n",
      "|    min|              0.92|\n",
      "|    max|              80.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.describe(\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             Fare|\n",
      "+-------+-----------------+\n",
      "|  count|              183|\n",
      "|   mean|78.68246885245901|\n",
      "| stddev|76.34784270040569|\n",
      "|    min|              0.0|\n",
      "|    max|         512.3292|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.describe(\"Fare\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnmEXLrSDTTd"
   },
   "source": [
    "### Normality test\n",
    "\n",
    "Check if \"Age\" and \"Fare\" have normal distribution, using Kolmogorov-Smirnov test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-U2RwXRejak3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(pValue=1.943689653671754e-11, statistic=0.9713276975967852)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KolmogorovSmirnovTest.test(titanic_df, \"Age\", \"norm\", 0.0, 1.0).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(pValue=8.816725127758218e-12, statistic=0.9890707515997943)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KolmogorovSmirnovTest.test(titanic_df, \"Fare\", \"norm\", 0.0, 1.0).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-values are very small, essentialy near zero, so for both variables we reject the null hypothesis, i.e. they have non-normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LABGbwAsNJCa"
   },
   "source": [
    "### Correlations\n",
    "\n",
    "Calculate Pearson correlation between pairs of features:\n",
    "- \"Age\" and \"Survived\"\n",
    "- \"Sex\" and \"Survived\" (remember to encode \"Sex\" attribute as 0/1 values)\n",
    "\n",
    "Which correlation is stronger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.IntegerType())\n",
    "def sex_to_integers(sex: str) -> int:\n",
    "    return int(sex == \"male\")  # male - 1, female - 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+\n",
      "| Age|Sex|Survived|\n",
      "+----+---+--------+\n",
      "|38.0|  0|       1|\n",
      "|35.0|  0|       1|\n",
      "|54.0|  1|       0|\n",
      "| 4.0|  0|       1|\n",
      "|58.0|  0|       1|\n",
      "+----+---+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df_encoded = (\n",
    "    titanic_df\n",
    "    .select(\"Age\", \"Sex\", \"Survived\")\n",
    "    .withColumn(\"Sex\", sex_to_integers(F.col(\"Sex\")))\n",
    ")\n",
    "\n",
    "titanic_df_encoded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wHUlmM-OjcBi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2540847542030532"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df_encoded.corr(\"Age\", \"Survived\", method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5324179744538412"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df_encoded.corr(\"Sex\", \"Survived\", method=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between \"Sex\" and \"Survived\" is stronger (larger absolute value), which is expected, as more women survived the Titanic sinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading from nonstandard formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [Wine dataset](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/wine.scale) ([UCI description](http://archive.ics.uci.edu/ml/datasets/Wine)), which is in the LibSVM (.scala) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "|  1.0|(13,[0,1,2,3,4,5,...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(label=1.0, features=SparseVector(13, {0: 0.6842, 1: -0.6166, 2: 0.1444, 3: -0.4845, 4: 0.2391, 5: 0.2552, 6: 0.1477, 7: -0.434, 8: 0.1861, 9: -0.256, 10: -0.0894, 11: 0.9414, 12: 0.1227}))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"wine.scala\"\n",
    "\n",
    "wine_df = (\n",
    "    spark.read\n",
    "    .format(\"libsvm\")\n",
    "    .option(\"numFeatures\", \"13\").load(filename)\n",
    ")\n",
    "\n",
    "wine_df.show(10)\n",
    "wine_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load [pre-formatted Wine dataset](https://gist.githubusercontent.com/tijptjik/9408623/raw/b237fa5848349a14a14e5d4107dc7897c21951f5/wine.csv) ([UCI description](http://archive.ics.uci.edu/ml/datasets/Wine)). Remember about deleting dots from the headers of the CSV file and splitting data into train and test set.\n",
    "\n",
    "Create a classification pipeline:\n",
    "1. Create pipeline with `VectorAssembler` and `DecisionTreeClassifier`.\n",
    "2. Use the pipeline to make predictions.\n",
    "3. Evaluate predictions using `MulticlassClassificationEvaluator`.\n",
    "4. Calculate accuracy and test error\n",
    "5. Print the structure of the trained decision tree, using the `toDebugString`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+----+----+---+-------+----------+--------------------+-------+---------+----+----+-------+\n",
      "|Wine|Alcohol|Malic_acid| Ash| Acl| Mg|Phenols|Flavanoids|Nonflavanoid_phenols|Proanth|Color_int| Hue|  OD|Proline|\n",
      "+----+-------+----------+----+----+---+-------+----------+--------------------+-------+---------+----+----+-------+\n",
      "|   1|  14.23|      1.71|2.43|15.6|127|    2.8|      3.06|                0.28|   2.29|     5.64|1.04|3.92|   1065|\n",
      "|   1|   13.2|      1.78|2.14|11.2|100|   2.65|      2.76|                0.26|   1.28|     4.38|1.05| 3.4|   1050|\n",
      "|   1|  13.16|      2.36|2.67|18.6|101|    2.8|      3.24|                 0.3|   2.81|     5.68|1.03|3.17|   1185|\n",
      "|   1|  14.37|      1.95| 2.5|16.8|113|   3.85|      3.49|                0.24|   2.18|      7.8|0.86|3.45|   1480|\n",
      "|   1|  13.24|      2.59|2.87|21.0|118|    2.8|      2.69|                0.39|   1.82|     4.32|1.04|2.93|    735|\n",
      "+----+-------+----------+----+----+---+-------+----------+--------------------+-------+---------+----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('Wine', 'int'), ('Alcohol', 'double'), ('Malic_acid', 'double'), ('Ash', 'double'), ('Acl', 'double'), ('Mg', 'int'), ('Phenols', 'double'), ('Flavanoids', 'double'), ('Nonflavanoid_phenols', 'double'), ('Proanth', 'double'), ('Color_int', 'double'), ('Hue', 'double'), ('OD', 'double'), ('Proline', 'int')]\n"
     ]
    }
   ],
   "source": [
    "filename = \"wine.csv\"\n",
    "\n",
    "wine_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(inferSchema=\"true\", header=\"true\")\n",
    "    .load(\"wine.csv\")\n",
    "    .withColumnRenamed(\"Malic.acid\", \"Malic_acid\")\n",
    "    .withColumnRenamed(\"Nonflavanoid.phenols\", \"Nonflavanoid_phenols\")\n",
    "    .withColumnRenamed(\"Color.int\", \"Color_int\")\n",
    ")\n",
    "\n",
    "train_df, test_df = wine_df.randomSplit([0.8, 0.2], seed=0)\n",
    "\n",
    "wine_df.show(5)\n",
    "print(wine_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wine_decision_tree(train_df, test_df):\n",
    "    num_classes = train_df.select(\"Wine\").distinct().count()\n",
    "    feature_cols = train_df.columns[1:]\n",
    "    \n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=feature_cols, \n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "    decision_tree = DecisionTreeClassifier(\n",
    "        labelCol=\"Wine\", \n",
    "        featuresCol=\"features\"\n",
    "    )\n",
    "    pipeline = Pipeline(stages=[assembler, decision_tree]) \n",
    "\n",
    "    model = pipeline.fit(train_df)\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"Wine\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"accuracy\"\n",
    "    )\n",
    "    accuracy = evaluator.evaluate(predictions) * 100\n",
    "    \n",
    "    return model, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_e8a5b53a7692, depth=5, numNodes=19, numClasses=4, numFeatures=13\n",
      "  If (feature 12 <= 755.0)\n",
      "   If (feature 6 <= 1.385)\n",
      "    If (feature 9 <= 3.77)\n",
      "     Predict: 2.0\n",
      "    Else (feature 9 > 3.77)\n",
      "     Predict: 3.0\n",
      "   Else (feature 6 > 1.385)\n",
      "    If (feature 0 <= 13.135)\n",
      "     Predict: 2.0\n",
      "    Else (feature 0 > 13.135)\n",
      "     If (feature 1 <= 1.6749999999999998)\n",
      "      Predict: 2.0\n",
      "     Else (feature 1 > 1.6749999999999998)\n",
      "      If (feature 0 <= 13.285)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 13.285)\n",
      "       Predict: 3.0\n",
      "  Else (feature 12 > 755.0)\n",
      "   If (feature 5 <= 1.6150000000000002)\n",
      "    If (feature 1 <= 1.62)\n",
      "     Predict: 2.0\n",
      "    Else (feature 1 > 1.62)\n",
      "     Predict: 3.0\n",
      "   Else (feature 5 > 1.6150000000000002)\n",
      "    If (feature 0 <= 11.98)\n",
      "     Predict: 2.0\n",
      "    Else (feature 0 > 11.98)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, accuracy = train_wine_decision_tree(train_df, test_df)\n",
    "\n",
    "tree_model = model.stages[1]\n",
    "print(tree_model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extend the pipeline from the previous task with `QuantileDiscretizer`\n",
    "2. Try using a few different numbers of buckets, which configuration gives the best results?\n",
    "3. Can you see any difference in the structure of the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binned_wine_decision_tree(train_df, test_df, num_buckets: int):\n",
    "    num_classes = train_df.select(\"Wine\").distinct().count()\n",
    "    feature_cols = train_df.columns[1:]\n",
    "    discretized_cols = [f\"{col}_disc\" for col in train_df.columns[1:]]\n",
    "    \n",
    "    discretizer = QuantileDiscretizer(\n",
    "        inputCols=feature_cols,\n",
    "        outputCols=discretized_cols,\n",
    "        numBuckets=num_buckets\n",
    "    )\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=discretized_cols, \n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "    decision_tree = DecisionTreeClassifier(\n",
    "        labelCol=\"Wine\", \n",
    "        featuresCol=\"features\",\n",
    "        \n",
    "    )\n",
    "    pipeline = Pipeline(stages=[discretizer, assembler, decision_tree]) \n",
    "\n",
    "    model = pipeline.fit(train_df)\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"Wine\", \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"accuracy\"\n",
    "    )\n",
    "    accuracy = evaluator.evaluate(predictions) * 100\n",
    "    \n",
    "    return model, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins: 2\n",
      "Accuracy: 88.89\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_7386f045b0d4, depth=5, numNodes=21, numClasses=4, numFeatures=13\n",
      "  If (feature 6 in {0.0})\n",
      "   If (feature 9 in {0.0})\n",
      "    If (feature 10 in {0.0})\n",
      "     If (feature 8 in {0.0})\n",
      "      If (feature 1 in {0.0})\n",
      "       Predict: 2.0\n",
      "      Else (feature 1 not in {0.0})\n",
      "       Predict: 3.0\n",
      "     Else (feature 8 not in {0.0})\n",
      "      Predict: 2.0\n",
      "    Else (feature 10 not in {0.0})\n",
      "     Predict: 2.0\n",
      "   Else (feature 9 not in {0.0})\n",
      "    If (feature 10 in {0.0})\n",
      "     Predict: 3.0\n",
      "    Else (feature 10 not in {0.0})\n",
      "     Predict: 2.0\n",
      "  Else (feature 6 not in {0.0})\n",
      "   If (feature 12 in {0.0})\n",
      "    Predict: 2.0\n",
      "   Else (feature 12 not in {0.0})\n",
      "    If (feature 0 in {0.0})\n",
      "     If (feature 2 in {0.0})\n",
      "      Predict: 2.0\n",
      "     Else (feature 2 not in {0.0})\n",
      "      If (feature 3 in {0.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 3 not in {0.0})\n",
      "       Predict: 2.0\n",
      "    Else (feature 0 not in {0.0})\n",
      "     Predict: 1.0\n",
      "\n",
      "\n",
      "Bins: 3\n",
      "Accuracy: 97.22\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_eebc94f1b12e, depth=5, numNodes=23, numClasses=4, numFeatures=13\n",
      "  If (feature 12 in {0.0,1.0})\n",
      "   If (feature 6 in {0.0})\n",
      "    If (feature 9 in {0.0})\n",
      "     Predict: 2.0\n",
      "    Else (feature 9 not in {0.0})\n",
      "     If (feature 3 in {0.0})\n",
      "      If (feature 0 in {0.0})\n",
      "       Predict: 3.0\n",
      "      Else (feature 0 not in {0.0})\n",
      "       Predict: 2.0\n",
      "     Else (feature 3 not in {0.0})\n",
      "      Predict: 3.0\n",
      "   Else (feature 6 not in {0.0})\n",
      "    If (feature 4 in {0.0,1.0})\n",
      "     Predict: 2.0\n",
      "    Else (feature 4 not in {0.0,1.0})\n",
      "     If (feature 0 in {0.0})\n",
      "      Predict: 2.0\n",
      "     Else (feature 0 not in {0.0})\n",
      "      If (feature 5 in {0.0})\n",
      "       Predict: 3.0\n",
      "      Else (feature 5 not in {0.0})\n",
      "       Predict: 1.0\n",
      "  Else (feature 12 not in {0.0,1.0})\n",
      "   If (feature 5 in {0.0})\n",
      "    If (feature 1 in {0.0})\n",
      "     Predict: 2.0\n",
      "    Else (feature 1 not in {0.0})\n",
      "     Predict: 3.0\n",
      "   Else (feature 5 not in {0.0})\n",
      "    If (feature 0 in {0.0})\n",
      "     Predict: 2.0\n",
      "    Else (feature 0 not in {0.0})\n",
      "     Predict: 1.0\n",
      "\n",
      "\n",
      "Bins: 4\n",
      "Accuracy: 91.67\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_17595af49d85, depth=5, numNodes=17, numClasses=4, numFeatures=13\n",
      "  If (feature 12 in {0.0,1.0,2.0})\n",
      "   If (feature 6 in {0.0})\n",
      "    If (feature 9 in {0.0})\n",
      "     Predict: 2.0\n",
      "    Else (feature 9 not in {0.0})\n",
      "     Predict: 3.0\n",
      "   Else (feature 6 not in {0.0})\n",
      "    If (feature 12 in {2.0})\n",
      "     If (feature 1 in {0.0})\n",
      "      Predict: 2.0\n",
      "     Else (feature 1 not in {0.0})\n",
      "      If (feature 6 in {1.0})\n",
      "       Predict: 2.0\n",
      "      Else (feature 6 not in {1.0})\n",
      "       Predict: 1.0\n",
      "    Else (feature 12 not in {2.0})\n",
      "     If (feature 11 in {0.0})\n",
      "      If (feature 2 in {0.0})\n",
      "       Predict: 2.0\n",
      "      Else (feature 2 not in {0.0})\n",
      "       Predict: 3.0\n",
      "     Else (feature 11 not in {0.0})\n",
      "      Predict: 2.0\n",
      "  Else (feature 12 not in {0.0,1.0,2.0})\n",
      "   Predict: 1.0\n",
      "\n",
      "\n",
      "Bins: 5\n",
      "Accuracy: 94.44\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_27fa1f631cdb, depth=5, numNodes=23, numClasses=4, numFeatures=13\n",
      "  If (feature 12 in {0.0,1.0,2.0})\n",
      "   If (feature 9 in {0.0,1.0})\n",
      "    If (feature 11 in {0.0})\n",
      "     If (feature 0 in {1.0})\n",
      "      Predict: 2.0\n",
      "     Else (feature 0 not in {1.0})\n",
      "      Predict: 3.0\n",
      "    Else (feature 11 not in {0.0})\n",
      "     Predict: 2.0\n",
      "   Else (feature 9 not in {0.0,1.0})\n",
      "    If (feature 6 in {0.0,1.0})\n",
      "     If (feature 2 in {0.0})\n",
      "      If (feature 3 in {1.0})\n",
      "       Predict: 2.0\n",
      "      Else (feature 3 not in {1.0})\n",
      "       Predict: 3.0\n",
      "     Else (feature 2 not in {0.0})\n",
      "      Predict: 3.0\n",
      "    Else (feature 6 not in {0.0,1.0})\n",
      "     If (feature 1 in {0.0,2.0})\n",
      "      Predict: 2.0\n",
      "     Else (feature 1 not in {0.0,2.0})\n",
      "      Predict: 1.0\n",
      "  Else (feature 12 not in {0.0,1.0,2.0})\n",
      "   If (feature 11 in {0.0,1.0})\n",
      "    If (feature 1 in {0.0,1.0})\n",
      "     Predict: 2.0\n",
      "    Else (feature 1 not in {0.0,1.0})\n",
      "     Predict: 3.0\n",
      "   Else (feature 11 not in {0.0,1.0})\n",
      "    If (feature 0 in {0.0})\n",
      "     Predict: 2.0\n",
      "    Else (feature 0 not in {0.0})\n",
      "     Predict: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_bins in range(2, 6):\n",
    "    print(\"Bins:\", num_bins)\n",
    "    model, accuracy = train_binned_wine_decision_tree(train_df, test_df, num_bins)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    tree_model = model.stages[2]\n",
    "    print(tree_model.toDebugString)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy changes quite a bit depending on number of bins, from 89% to 97%. Highest one is achieved with 3 bins.\n",
    "\n",
    "Tree structure also changes, in terms of both number of bins used for splits and depth of the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0Ax7J2kjiQX"
   },
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline consisting of `Tokenizer`, `HashingTF`, `IDF`, `StringIndexer` and `LogisticRegression`. Use [the Sentiment 140 dataset](http://help.sentiment140.com/for-students/).\n",
    "\n",
    "What is the accuracy of this classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "S9QbF10DjwU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0|@switchfoot http:...|\n",
      "|    0|is upset that he ...|\n",
      "|    0|@Kenichan I dived...|\n",
      "|    0|my whole body fee...|\n",
      "|    0|@nationwideclass ...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('label', 'int'), ('text', 'string')]\n"
     ]
    }
   ],
   "source": [
    "columns = [\"label\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "\n",
    "train_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(inferSchema=\"true\", header=\"false\")\n",
    "    .load(\"sentiment_train.csv\")\n",
    ")\n",
    "for old, new in zip(train_df.columns, columns):\n",
    "    train_df = train_df.withColumnRenamed(old, new)\n",
    "\n",
    "\n",
    "test_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(inferSchema=\"true\", header=\"false\")\n",
    "    .load(\"sentiment_test.csv\")\n",
    ")\n",
    "for old, new in zip(test_df.columns, columns):\n",
    "    test_df = test_df.withColumnRenamed(old, new)\n",
    "\n",
    "    \n",
    "train_df = train_df.select(\"label\", \"text\")\n",
    "test_df = test_df.select(\"label\", \"text\")\n",
    "\n",
    "train_df.show(5)\n",
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no class 2 (neutral sentiment) in the training set, I remove it from the test set with `handleInvalid=\"skip\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    inputCol=\"text\", \n",
    "    outputCol=\"tokens\"\n",
    ")\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol=\"tokens\", \n",
    "    outputCol=\"features\", \n",
    "    numFeatures=50\n",
    ")\n",
    "idf = IDF(\n",
    "    inputCol=\"features\", \n",
    "    outputCol=\"final_features\"\n",
    ")\n",
    "string_indexer = StringIndexer(\n",
    "    inputCol=\"label\", \n",
    "    outputCol=\"final_label\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "classifier = LogisticRegression(\n",
    "    featuresCol=\"final_features\", \n",
    "    labelCol=\"final_label\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashing_tf, idf, string_indexer, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.20\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"final_label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator.evaluate(predictions) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Empty_ADZD-6-MLlib.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
